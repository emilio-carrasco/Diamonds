{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpia_catergoricas(data):\n",
    "\n",
    "    def limpia_color(df):\n",
    "        return df.apply(lambda x: abs(ord(x.upper())-ord('Z')))\n",
    "\n",
    "\n",
    "    def limpia_corte(df):\n",
    "        dict_cut={'Ideal':5,'Premium':4,  'Very Good':3,'Good':2,  'Fair':1, 'Poor':0}\n",
    "        return df.map(dict_cut)\n",
    "\n",
    "    def limpia_claridad(df):\n",
    "        dict_clarity={'I3':0, 'I2':1, 'I1':2, 'SI2':3, 'SI1':4, 'VS2':5, \n",
    "                    'VS1':6, 'VVS2':7, 'VVS1':8, 'IF':9,'F':10}\n",
    "        return df.map(dict_clarity)\n",
    "\n",
    "    data.color=limpia_color(data.color)\n",
    "    data.cut=limpia_corte(data.cut)\n",
    "    data.clarity=limpia_claridad(data.clarity)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def limpia_dimensiones(data):\n",
    "    data.columns=['id', 'carat', 'cut', 'color', 'clarity', 'depth_p', 'table_p', 'x', 'y',\n",
    "       'z', 'price']\n",
    "    return data[['cut', 'color', 'clarity', 'carat', 'depth_p', 'table_p','price']]\n",
    "\n",
    "def incluye_ideal_table(data,ideal):\n",
    "    data['ideal_table']=abs(data.table_p-ideal)\n",
    "    return data.drop('table_p',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       cut  color  clarity  carat  depth_p  table_p  price\n",
       "0        4     19        6   1.01     62.7     58.0  8.754\n",
       "1        2     19        5   0.60     64.3     57.0  7.492\n",
       "2        4     18        3   1.60     59.4     59.0  9.010\n",
       "3        3     16        6   0.30     63.5     58.0  6.227\n",
       "4        3     20        3   1.00     62.8     57.0  8.314\n",
       "...    ...    ...      ...    ...      ...      ...    ...\n",
       "40450    5     21        5   0.51     62.5     55.0  7.412\n",
       "40451    5     18        5   0.80     62.1     54.0  8.016\n",
       "40452    4     19        3   1.53     58.7     59.0  9.070\n",
       "40453    5     17        5   1.51     61.6     54.0  9.199\n",
       "40454    5     21        5   1.00     62.1     57.0  8.932\n",
       "\n",
       "[40455 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>carat</th>\n      <th>depth_p</th>\n      <th>table_p</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>19</td>\n      <td>6</td>\n      <td>1.01</td>\n      <td>62.7</td>\n      <td>58.0</td>\n      <td>8.754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>19</td>\n      <td>5</td>\n      <td>0.60</td>\n      <td>64.3</td>\n      <td>57.0</td>\n      <td>7.492</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>18</td>\n      <td>3</td>\n      <td>1.60</td>\n      <td>59.4</td>\n      <td>59.0</td>\n      <td>9.010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>16</td>\n      <td>6</td>\n      <td>0.30</td>\n      <td>63.5</td>\n      <td>58.0</td>\n      <td>6.227</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>20</td>\n      <td>3</td>\n      <td>1.00</td>\n      <td>62.8</td>\n      <td>57.0</td>\n      <td>8.314</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40450</th>\n      <td>5</td>\n      <td>21</td>\n      <td>5</td>\n      <td>0.51</td>\n      <td>62.5</td>\n      <td>55.0</td>\n      <td>7.412</td>\n    </tr>\n    <tr>\n      <th>40451</th>\n      <td>5</td>\n      <td>18</td>\n      <td>5</td>\n      <td>0.80</td>\n      <td>62.1</td>\n      <td>54.0</td>\n      <td>8.016</td>\n    </tr>\n    <tr>\n      <th>40452</th>\n      <td>4</td>\n      <td>19</td>\n      <td>3</td>\n      <td>1.53</td>\n      <td>58.7</td>\n      <td>59.0</td>\n      <td>9.070</td>\n    </tr>\n    <tr>\n      <th>40453</th>\n      <td>5</td>\n      <td>17</td>\n      <td>5</td>\n      <td>1.51</td>\n      <td>61.6</td>\n      <td>54.0</td>\n      <td>9.199</td>\n    </tr>\n    <tr>\n      <th>40454</th>\n      <td>5</td>\n      <td>21</td>\n      <td>5</td>\n      <td>1.00</td>\n      <td>62.1</td>\n      <td>57.0</td>\n      <td>8.932</td>\n    </tr>\n  </tbody>\n</table>\n<p>40455 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df=limpia_catergoricas(df)\n",
    "df=limpia_dimensiones(df)\n",
    "\n",
    "df_size = df[df.carat - np.floor(df.carat) == 0]\n",
    "df_off = df[df.carat - np.floor(df.carat) != 0]\n",
    "#df=df_size\n",
    "#df=df_off\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54323 . connected.\n",
      "Warning: Your H2O cluster version is too old (11 months and 7 days)! Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "--------------------------  ------------------------------------------------------------------\nH2O_cluster_uptime:         4 mins 43 secs\nH2O_cluster_timezone:       Europe/Madrid\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.30.0.4\nH2O_cluster_version_age:    11 months and 7 days !!!\nH2O_cluster_name:           H2O_from_python_emilio_6b7muq\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    0\nH2O_cluster_total_cores:    8\nH2O_cluster_allowed_cores:  8\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://localhost:54323\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nH2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\nPython_version:             3.9.4 final\n--------------------------  ------------------------------------------------------------------",
      "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>4 mins 43 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Madrid</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.30.0.4</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>11 months and 7 days !!!</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_emilio_6b7muq</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>0</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>8</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://localhost:54323</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>H2O_API_Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python_version:</td>\n<td>3.9.4 final</td></tr></table></div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "h2o.init(ip=\"localhost\", port=54323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "H2OResponseError",
     "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Total input file size of 1.3 MB is much larger than total cluster memory of Zero  , please use either a larger cluster or smaller data.\n  Request: POST /3/Parse\n    data: {'destination_frame': 'Key_Frame__upload_aaba0099ca02d395d0dcc4d4a36849c6.hex', 'parse_type': 'CSV', 'separator': '44', 'single_quotes': 'False', 'check_header': '1', 'number_columns': '7', 'chunk_size': '4194304', 'delete_on_done': 'True', 'blocking': 'False', 'column_types': '[\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\"]', 'column_names': '[\"cut\",\"color\",\"clarity\",\"carat\",\"depth_p\",\"table_p\",\"price\"]', 'source_frames': '[\"upload_aaba0099ca02d395d0dcc4d4a36849c6\"]'}\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2d58509e248b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdia\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH2OFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Set the predictors and response;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set the response as a factor:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# Indicate that this is an actual frame, allowing typechecks to be made\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpython_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             self._upload_python_object(python_obj, destination_frame, header, separator,\n\u001b[0m\u001b[1;32m    109\u001b[0m                                        column_names, column_types, na_strings, skipped_columns)\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_python_object\u001b[0;34m(self, python_obj, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mcsv_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mtmp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# close the streams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upload_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# delete the tmp file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_upload_parse\u001b[0;34m(self, path, destination_frame, header, sep, column_names, column_types, na_strings, skipped_columns)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/PostFile\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mrawkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"destination_frame\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, rawkey, destination_frame, header, separator, column_names, column_types, na_strings, skipped_columns, custom_non_data_line_markers)\u001b[0m\n\u001b[1;32m    443\u001b[0m         setup = h2o.parse_setup(rawkey, destination_frame, header, separator, column_names, column_types, na_strings,\n\u001b[1;32m    444\u001b[0m                                 skipped_columns, custom_non_data_line_markers)\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/frame.py\u001b[0m in \u001b[0;36m_parse_raw\u001b[0;34m(self, setup)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_frames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_quoted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source_frames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mH2OJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST /3/Parse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Parse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;31m# Need to return a Frame here for nearly all callers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# ... but job stats returns only a dest_key, requiring another REST call to get nrow/ncol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/h2o.py\u001b[0m in \u001b[0;36mapi\u001b[0;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0msave_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/backend/connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[0;34m(response, save_to)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m412\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH2OErrorV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2OModelBuilderErrorV3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Total input file size of 1.3 MB is much larger than total cluster memory of Zero  , please use either a larger cluster or smaller data.\n  Request: POST /3/Parse\n    data: {'destination_frame': 'Key_Frame__upload_aaba0099ca02d395d0dcc4d4a36849c6.hex', 'parse_type': 'CSV', 'separator': '44', 'single_quotes': 'False', 'check_header': '1', 'number_columns': '7', 'chunk_size': '4194304', 'delete_on_done': 'True', 'blocking': 'False', 'column_types': '[\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\",\"Numeric\"]', 'column_names': '[\"cut\",\"color\",\"clarity\",\"carat\",\"depth_p\",\"table_p\",\"price\"]', 'source_frames': '[\"upload_aaba0099ca02d395d0dcc4d4a36849c6\"]'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dia=h2o.H2OFrame(df)\n",
    "\n",
    "\n",
    "# Set the predictors and response;\n",
    "# set the response as a factor:\n",
    "\n",
    "predictors = ['cut','color','clarity','carat','depth_p','table_p']\n",
    "response = 'price'\n",
    "\n",
    "# Split the dataset into a train and valid set:\n",
    "train, valid = dia.split_frame(ratios=[.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3536571a9bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">  cut</th><th style=\"text-align: right;\">  color</th><th style=\"text-align: right;\">  clarity</th><th style=\"text-align: right;\">  carat</th><th style=\"text-align: right;\">  depth_p</th><th style=\"text-align: right;\">  table_p</th><th style=\"text-align: right;\">  price</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">     19</td><td style=\"text-align: right;\">        6</td><td style=\"text-align: right;\">   1.01</td><td style=\"text-align: right;\">     62.7</td><td style=\"text-align: right;\">       58</td><td style=\"text-align: right;\">  8.754</td></tr>\n<tr><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">     19</td><td style=\"text-align: right;\">        5</td><td style=\"text-align: right;\">   0.6 </td><td style=\"text-align: right;\">     64.3</td><td style=\"text-align: right;\">       57</td><td style=\"text-align: right;\">  7.492</td></tr>\n<tr><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">   1   </td><td style=\"text-align: right;\">     62.8</td><td style=\"text-align: right;\">       57</td><td style=\"text-align: right;\">  8.314</td></tr>\n<tr><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">   0.7 </td><td style=\"text-align: right;\">     62.1</td><td style=\"text-align: right;\">       59</td><td style=\"text-align: right;\">  7.694</td></tr>\n<tr><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">     16</td><td style=\"text-align: right;\">        6</td><td style=\"text-align: right;\">   0.71</td><td style=\"text-align: right;\">     63.3</td><td style=\"text-align: right;\">       55</td><td style=\"text-align: right;\">  7.54 </td></tr>\n<tr><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">     19</td><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">   0.9 </td><td style=\"text-align: right;\">     63  </td><td style=\"text-align: right;\">       57</td><td style=\"text-align: right;\">  8.211</td></tr>\n<tr><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">     18</td><td style=\"text-align: right;\">        3</td><td style=\"text-align: right;\">   2.01</td><td style=\"text-align: right;\">     63.4</td><td style=\"text-align: right;\">       57</td><td style=\"text-align: right;\">  9.687</td></tr>\n<tr><td style=\"text-align: right;\">    5</td><td style=\"text-align: right;\">     19</td><td style=\"text-align: right;\">        5</td><td style=\"text-align: right;\">   0.56</td><td style=\"text-align: right;\">     61.9</td><td style=\"text-align: right;\">       55</td><td style=\"text-align: right;\">  7.365</td></tr>\n<tr><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">     18</td><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">   1.5 </td><td style=\"text-align: right;\">     64.9</td><td style=\"text-align: right;\">       57</td><td style=\"text-align: right;\">  9.001</td></tr>\n<tr><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">     22</td><td style=\"text-align: right;\">        4</td><td style=\"text-align: right;\">   0.3 </td><td style=\"text-align: right;\">     63  </td><td style=\"text-align: right;\">       58</td><td style=\"text-align: right;\">  6.564</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model   \n",
    "dia_drf = H2ORandomForestEstimator(ntrees=10000,max_depth=2000,nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "drf Model Build progress: | (failed)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Job with key $03017f00000134d4ffffffff$_a24af904663bf87c793748d41d3e496e failed with an exception: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: DRF_model_python_1620499930463_3_cv_1.  Details: ERRR on field: _ntrees: The tree model will not fit in the driver node's memory (171.1 KB per tree x 10000 > 117.3 MB) - try decreasing ntrees and/or max_depth or increasing min_rows!\n\nstacktrace: \nwater.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: DRF_model_python_1620499930463_3_cv_1.  Details: ERRR on field: _ntrees: The tree model will not fit in the driver node's memory (171.1 KB per tree x 10000 > 117.3 MB) - try decreasing ntrees and/or max_depth or increasing min_rows!\n\n\tat water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:19)\n\tat hex.tree.SharedTree.doScoringAndSaveModel(SharedTree.java:721)\n\tat hex.tree.SharedTree$Driver.scoreAndBuildTrees(SharedTree.java:435)\n\tat hex.tree.SharedTree$Driver.computeImpl(SharedTree.java:362)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:248)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1557)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-72ec71c3f8d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdia_drf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[1;32m    113\u001b[0m                                  \u001b[0mvalidation_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_runtime_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_runtime_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                                  ignored_columns=ignored_columns, model_id=model_id, verbose=verbose)\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     def train_segments(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None,\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/estimators/estimator_base.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, parms, verbose)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_model_scoring_history\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET /%d/Models/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FAILED\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0m\u001b[1;32m     78\u001b[0m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[1;32m     79\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000134d4ffffffff$_a24af904663bf87c793748d41d3e496e failed with an exception: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: DRF_model_python_1620499930463_3_cv_1.  Details: ERRR on field: _ntrees: The tree model will not fit in the driver node's memory (171.1 KB per tree x 10000 > 117.3 MB) - try decreasing ntrees and/or max_depth or increasing min_rows!\n\nstacktrace: \nwater.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DRF model: DRF_model_python_1620499930463_3_cv_1.  Details: ERRR on field: _ntrees: The tree model will not fit in the driver node's memory (171.1 KB per tree x 10000 > 117.3 MB) - try decreasing ntrees and/or max_depth or increasing min_rows!\n\n\tat water.exceptions.H2OModelBuilderIllegalArgumentException.makeFromBuilder(H2OModelBuilderIllegalArgumentException.java:19)\n\tat hex.tree.SharedTree.doScoringAndSaveModel(SharedTree.java:721)\n\tat hex.tree.SharedTree$Driver.scoreAndBuildTrees(SharedTree.java:435)\n\tat hex.tree.SharedTree$Driver.computeImpl(SharedTree.java:362)\n\tat hex.ModelBuilder$Driver.compute2(ModelBuilder.java:248)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1557)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "dia_drf.train(x=predictors, y=response, training_frame=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5a1ec1a876cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdia_drf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iron/lib/python3.9/site-packages/h2o/model/model_base.py\u001b[0m in \u001b[0;36mmodel_performance\u001b[0;34m(self, test_data, train, valid, xval)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH2OFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`test_data` must be of type H2OFrame.  Got: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response_column_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response_column_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WARNING: Model metrics cannot be calculated and metric_json is empty due to the absence of the response column in your dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "performance = dia_drf.model_performance(test_data=valid)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.read_csv('./data/test.csv')\n",
    "x_test=limpia_catergoricas(x_test)\n",
    "x_test=h2o.H2OFrame(x_test)\n",
    "\n",
    "\n",
    "df_sub=pd.DataFrame(regr.predict(x_test))\n",
    "df_sub.reset_index(inplace=True)\n",
    "df_sub.columns=['id','price']\n",
    "# Generate predictions on a validation set (if necessary):\n",
    "pred = dia_drf.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 20000, num = 100)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 101, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "random_grid = {'n_estimators': [1000],\n",
    "               'max_features': [6],\n",
    "               'max_depth': [100],\n",
    "               'min_samples_split': [10],\n",
    "               'min_samples_leaf': [3],\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 1, cv = 3, verbose=3, n_jobs = -1, )\n",
    "\n",
    "x=df.drop('price',axis=1)\n",
    "y=df.price\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "duration=1\n",
    "freq=440\n",
    "os.system('play -nq -t  alsa synth {} sine {}'.format(duration,freq))\n",
    "os.system('play -nq -t  alsa synth {} sine {}'.format(duration,2*freq))\n",
    "os.system('play -nq -t  alsa synth {} sine {}'.format(duration,freq))\n",
    "\n",
    "mse(y_test,rf_random.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.008498457654443766"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "x=df.drop('price',axis=1)\n",
    "y=df.price\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=23)\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=2000, bootstrap=True,max_features=5,min_samples_split=2, min_samples_leaf=1, warm_start=True)\n",
    "regr.fit(x_train, y_train)\n",
    "mse(y_test,regr.predict(x_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.read_csv('./data/test.csv')\n",
    "x_test=limpia_catergoricas(x_test)\n",
    "x_test=h2o.H2OFrame(x_test)\n",
    "=regr.predict())\n",
    "# Eval performance:\n",
    "y_tests = dia_drf.model_performance(x_test)\n",
    "df_sub.reset_index(inplace=True)\n",
    "df_sub.columns=['id','price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size = df[df.carat - np.floor(df.carat) == 0]\n",
    "df_off = df[df.carat - np.floor(df.carat) != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('./out/sub_1stramforestn_estimators=2000max_features=4min_samples_split=20warm_start=True.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9686\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1ca7a97bafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloguniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Init Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, sgd\n",
    "\n",
    "# HyperOpt\n",
    "from hyperopt import hp\n",
    "\n",
    "# Sklearn stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load and split dataset\n",
    "x=df.drop('price',axis=1)\n",
    "y=df.price\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=23)\n",
    "\n",
    "# Penalizer for SGD\n",
    "penalty = 'l2'\n",
    "\n",
    "# Search space of \"loss functions\"\n",
    "# Different loss variations are defined, each one\n",
    "# with an specific probability to be selected\n",
    "# In this case, \"hinge\" is prioritized with respect the others\n",
    "loss = hp.pchoice('loss', [(0.50, 'hinge'), \n",
    "                           (0.25, 'log'), \n",
    "                           (0.25, 'huber')])\n",
    "\n",
    "# Search space for alpha value is definied\n",
    "# with a log-uniform function\n",
    "print(max(y)/5)\n",
    "\n",
    "alpha = hp.loguniform('alpha', low=min(y)/5, high=max(5)*5)\n",
    "\n",
    "# Init Estimator\n",
    "# The classifier is passed with its respective hyperparameters\n",
    "model = HyperoptEstimator(classifier=sgd('my_sgd', \n",
    "                                         penalty=penalty, \n",
    "                                         loss=loss, \n",
    "                                         alpha=alpha), \n",
    "                          max_evals=10, \n",
    "                          trial_timeout=30)\n",
    "\n",
    "# Training\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Results\n",
    "print(f\"Training score: {model.score(x_train, y_train)}\")\n",
    "print(f\"Test score: {model.socre(x_test, y_test)}\")\n",
    "\n",
    "# Optimal configuration\n",
    "print(f\"Optimal configuration: {model.best_model()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_test=pd.read_csv('./data/test.csv')\n",
    "\n",
    "X_test=limpia_catergoricas(X_test)\n",
    "\n",
    "X_test.columns=['id', 'carat', 'cut', 'color', 'clarity', 'depth_p', 'table_p', 'x', 'y', 'z']\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=limpia_catergoricas(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-04a266f9eb84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "df_sub=pd.DataFrame(lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.columns=['id','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('./out/sub1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd0582a2f9403bdfdfdb7dd603329d72f45f6537b93af78e4d851b5fcfa43d5c8ea",
   "display_name": "Python 3.9.4 64-bit ('iron': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}